<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8" />
  <title>Многофункциональное распознавание</title>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background: #333;
      color: #fff;
      font-family: sans-serif;
    }
    #container {
      position: relative;
      width: 100vw;
      height: 100vh;
      background: #000;
    }
    /* Видео и все canvas – зеркальное отображение */
    video, canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: scaleX(-1);
    }
    /* Canvas для оверлеев (лица, объекты) */
    #overlay {
      z-index: 15;
      pointer-events: none;
    }
    /* Информационный блок */
    #info {
      position: absolute;
      top: 10px;
      left: 10px;
      background: rgba(0,0,0,0.5);
      padding: 5px 10px;
      border-radius: 4px;
      z-index: 20;
    }
    /* Кнопки управления */
    #fullscreenBtn, #switchCameraBtn {
      position: absolute;
      top: 10px;
      z-index: 20;
      padding: 10px 20px;
      background: rgba(0, 0, 0, 0.7);
      color: #fff;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 16px;
    }
    #fullscreenBtn {
      right: 10px;
    }
    #switchCameraBtn {
      right: 150px;
    }
    #fullscreenBtn:hover, #switchCameraBtn:hover {
      background: rgba(0, 0, 0, 0.9);
    }
  </style>
</head>
<body>
  <div id="container">
    <!-- Видео с камеры -->
    <video id="video" autoplay playsinline muted></video>
    <!-- Canvas для отрисовки видео и рамок рук -->
    <canvas id="output"></canvas>
    <!-- Canvas для рисования линий (например, по жесту) -->
    <canvas id="drawLayer"></canvas>
    <!-- Дополнительный canvas для оверлеев (лица, объекты) -->
    <canvas id="overlay"></canvas>
    <div id="info">
      Лица: зелёная – спокойные, красная – негативные<br>
      Объекты: жёлтые – обычные, красные – опасные<br>
      Жесты: два раза сжать/разжать кулак + указательный = рисование; OK = очистка<br>
      Кнопки: "Повернуть камеру", "Полный экран"
    </div>
    <button id="switchCameraBtn">Повернуть камеру</button>
    <button id="fullscreenBtn">Полный экран</button>
  </div>

  <!-- Подключение библиотек -->
  <!-- Mediapipe Hands -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <!-- Face API (убедитесь, что модели доступны по пути /models) -->
  <script src="https://unpkg.com/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <!-- TensorFlow.js и COCO-SSD -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <script>
    // Элементы страницы
    const videoElement = document.getElementById('video');
    const outputCanvas = document.getElementById('output');
    const drawCanvas = document.getElementById('drawLayer');
    const overlayCanvas = document.getElementById('overlay');
    const infoDiv = document.getElementById('info');
    const fullscreenBtn = document.getElementById('fullscreenBtn');
    const switchCameraBtn = document.getElementById('switchCameraBtn');

    const outputCtx = outputCanvas.getContext('2d');
    const drawCtx = drawCanvas.getContext('2d');
    const overlayCtx = overlayCanvas.getContext('2d');

    // Режим камеры: "user" (передняя) или "environment" (задняя)
    let currentFacingMode = "user";
    let cameraInstance;

    // Полноэкранный режим
    fullscreenBtn.addEventListener('click', () => {
      if (document.fullscreenElement) {
        document.exitFullscreen();
      } else {
        document.getElementById('container').requestFullscreen();
      }
    });

    // Запрос доступа к камере и запуск
    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { width: 640, height: 480, facingMode: currentFacingMode },
          audio: false
        });
        videoElement.srcObject = stream;
        await videoElement.play();
      } catch (err) {
        console.error("Ошибка доступа к камере:", err);
        return;
      }
      if (cameraInstance) {
        cameraInstance.stop();
      }
      cameraInstance = new Camera(videoElement, {
        onFrame: async () => {
          await hands.send({ image: videoElement });
        },
        width: 640,
        height: 480,
        facingMode: currentFacingMode
      });
      cameraInstance.start();
    }

    // Переключение камеры
    switchCameraBtn.addEventListener('click', () => {
      currentFacingMode = (currentFacingMode === "user") ? "environment" : "user";
      startCamera();
    });

    // Изменение размеров canvas
    function resizeCanvases() {
      const width = videoElement.videoWidth || window.innerWidth;
      const height = videoElement.videoHeight || window.innerHeight;
      outputCanvas.width = width;
      outputCanvas.height = height;
      drawCanvas.width = width;
      drawCanvas.height = height;
      overlayCanvas.width = width;
      overlayCanvas.height = height;
    }

    // ------------------ Mediapipe Hands (распознавание руки и жесты) ------------------
    let fistCount = 0;
    let gestureActive = false;
    let lastFistState = false;
    let lastTimeFist = 0;

    function isFingerExtended(landmarks, pipIdx, tipIdx) {
      const pip = landmarks[pipIdx];
      const tip = landmarks[tipIdx];
      const wrist = landmarks[0];
      const distTip = Math.hypot(tip.x - wrist.x, tip.y - wrist.y);
      const distPip = Math.hypot(pip.x - wrist.x, pip.y - wrist.y);
      return distTip > distPip * 1.3;
    }
    function isFist(landmarks) {
      const fingers = [
        { pip: 6, tip: 8 },
        { pip: 10, tip: 12 },
        { pip: 14, tip: 16 },
        { pip: 18, tip: 20 }
      ];
      let thumbExtended = isFingerExtended(landmarks, 2, 4);
      let othersFolded = fingers.every(f => !isFingerExtended(landmarks, f.pip, f.tip));
      return (!thumbExtended) && othersFolded;
    }
    function isIndexPointing(landmarks) {
      const indexExtended = isFingerExtended(landmarks, 6, 8);
      const othersFolded = [{ pip: 10, tip: 12 }, { pip: 14, tip: 16 }, { pip: 18, tip: 20 }]
                              .every(f => !isFingerExtended(landmarks, f.pip, f.tip));
      return indexExtended && othersFolded;
    }
    function isOkGesture(landmarks) {
      const thumbTip = landmarks[4];
      const indexTip = landmarks[8];
      const dx = thumbTip.x - indexTip.x;
      const dy = thumbTip.y - indexTip.y;
      const dist = Math.hypot(dx, dy);
      return dist < 0.05;
    }

    const hands = new Hands({
      locateFile: (file) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
      }
    });
    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.7
    });
    hands.onResults((results) => {
      if (!outputCanvas.width || !outputCanvas.height) {
        resizeCanvases();
      }
      outputCtx.save();
      outputCtx.clearRect(0, 0, outputCanvas.width, outputCanvas.height);
      outputCtx.drawImage(results.image, 0, 0, outputCanvas.width, outputCanvas.height);

      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];
        let minX = 1, minY = 1, maxX = 0, maxY = 0;
        landmarks.forEach(pt => {
          if (pt.x < minX) minX = pt.x;
          if (pt.y < minY) minY = pt.y;
          if (pt.x > maxX) maxX = pt.x;
          if (pt.y > maxY) maxY = pt.y;
        });
        const boxX = minX * outputCanvas.width;
        const boxY = minY * outputCanvas.height;
        const boxW = (maxX - minX) * outputCanvas.width;
        const boxH = (maxY - minY) * outputCanvas.height;
        outputCtx.strokeStyle = 'lime';
        outputCtx.lineWidth = 3;
        outputCtx.strokeRect(boxX, boxY, boxW, boxH);

        const now = Date.now();
        if (now - lastTimeFist > 700) {
          const fist = isFist(landmarks);
          if (fist !== lastFistState) {
            lastFistState = fist;
            lastTimeFist = now;
            if (fist) {
              fistCount++;
              console.log("Кулак обнаружен. Счёт:", fistCount);
            }
          }
        }
        if (!gestureActive && fistCount >= 2 && isIndexPointing(landmarks)) {
          gestureActive = true;
          console.log("Режим рисования активирован");
        }
        if (gestureActive) {
          const indexTip = landmarks[8];
          const x = indexTip.x * drawCanvas.width;
          const y = indexTip.y * drawCanvas.height;
          drawCtx.fillStyle = 'black';
          drawCtx.beginPath();
          drawCtx.arc(x, y, 4, 0, 2 * Math.PI);
          drawCtx.fill();
        }
        if (gestureActive && isOkGesture(landmarks)) {
          console.log("Жест OK обнаружен, очистка холста");
          drawCtx.clearRect(0, 0, drawCanvas.width, drawCanvas.height);
          gestureActive = false;
          fistCount = 0;
        }
      }
      outputCtx.restore();
    });

    // ------------------ Распознавание лиц и объектов ------------------
    let cocoModel = null;
    // Список опасных/убийственных объектов (можно расширять)
    const dangerousObjects = ['knife', 'scissors', 'gun'];

    async function loadModels() {
      // Загрузка моделей для face-api.js – разместите файлы моделей в папке "models"
      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
      await faceapi.nets.ageGenderNet.loadFromUri('/models');
      await faceapi.nets.faceExpressionNet.loadFromUri('/models');
      // Загрузка модели COCO‑SSD
      cocoModel = await cocoSsd.load();
      console.log("Все модели загружены");
    }

    async function detectFaces() {
      if (videoElement.readyState < 2) return;
      const detections = await faceapi
        .detectAllFaces(videoElement, new faceapi.TinyFaceDetectorOptions())
        .withAgeAndGender()
        .withFaceExpressions();
      // Очищаем overlay
      overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
      detections.forEach(detection => {
        const { age, expressions, detection: box } = detection;
        // Определяем доминирующую эмоцию
        const sorted = Object.entries(expressions).sort((a, b) => b[1] - a[1]);
        const emotion = sorted[0][0];
        // Если эмоция "angry" или "disgusted" – красная рамка, иначе зелёная
        const color = (emotion === 'angry' || emotion === 'disgusted') ? 'red' : 'lime';
        overlayCtx.strokeStyle = color;
        overlayCtx.lineWidth = 2;
        overlayCtx.strokeRect(box.box.x, box.box.y, box.box.width, box.box.height);
        overlayCtx.fillStyle = color;
        overlayCtx.font = "16px sans-serif";
        overlayCtx.fillText(`Возраст: ${Math.round(age)}, ${emotion}`, box.box.x, box.box.y - 5);
      });
    }

    async function detectObjects() {
      if (!cocoModel) return;
      const predictions = await cocoModel.detect(videoElement);
      predictions.forEach(pred => {
        const [x, y, width, height] = pred.bbox;
        let color = 'yellow';
        let label = pred.class;
        // Если класс объекта входит в список опасных – рамка красная с подписью "опасный"
        if (dangerousObjects.includes(pred.class.toLowerCase())) {
          color = 'red';
          label = `опасный: ${pred.class}`;
        }
        overlayCtx.strokeStyle = color;
        overlayCtx.lineWidth = 2;
        overlayCtx.strokeRect(x, y, width, height);
        overlayCtx.fillStyle = color;
        overlayCtx.font = "16px sans-serif";
        overlayCtx.fillText(label, x, y - 5);
      });
    }

    async function detectionLoop() {
      await detectFaces();
      await detectObjects();
      requestAnimationFrame(detectionLoop);
    }

    loadModels().then(() => {
      detectionLoop();
    });

    window.addEventListener('resize', resizeCanvases);

    // Запуск камеры
    startCamera();
  </script>
</body>
</html>
