<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8" />
  <title>Улучшенное распознавание жестов, лиц и объектов</title>
  <style>
    * { margin: 0; padding: 0; }
    body, html {
      width: 100%;
      height: 100%;
      background: #333;
      color: #fff;
      font-family: sans-serif;
      overflow: hidden;
    }
    #container {
      position: relative;
      width: 100vw;
      height: 100vh;
      background: #000;
    }
    video {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      /* Можно убрать зеркальное отображение, если нужно */
      transform: scaleX(-1);
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      pointer-events: none;
    }
    /* Определяем порядок: video < output < drawLayer < overlay */
    #output { z-index: 1; }
    #drawLayer { z-index: 2; }
    #overlay { z-index: 3; }
    #info {
      position: absolute;
      top: 10px;
      left: 10px;
      background: rgba(0, 0, 0, 0.5);
      padding: 5px 10px;
      border-radius: 4px;
      z-index: 10;
      font-size: 14px;
    }
    .btn {
      position: absolute;
      top: 10px;
      z-index: 20;
      padding: 10px 20px;
      background: rgba(0, 0, 0, 0.7);
      color: #fff;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 16px;
    }
    #fullscreenBtn { right: 10px; }
    #switchCameraBtn { right: 150px; }
    .btn:hover { background: rgba(0, 0, 0, 0.9); }
  </style>
</head>
<body>
  <div id="container">
    <!-- Видео с камеры -->
    <video id="video" autoplay playsinline muted></video>
    <!-- Canvas для отрисовки результатов Mediapipe (рука) -->
    <canvas id="output"></canvas>
    <!-- Canvas для рисования линий (режим рисования, не очищается при обновлении) -->
    <canvas id="drawLayer"></canvas>
    <!-- Canvas для отрисовки рамок лиц и объектов -->
    <canvas id="overlay"></canvas>
    <div id="info">
      Жесты: дважды сжать кулак + указательный = режим рисования; OK = очистка<br>
      Лицо: возраст и эмоция; Объекты: опасный (красный), еда (зелёный), остальные (жёлтый)
    </div>
    <button id="fullscreenBtn" class="btn">Полный экран</button>
    <button id="switchCameraBtn" class="btn">Сменить камеру</button>
  </div>

  <!-- Подключаем библиотеки -->
  <!-- Mediapipe Hands и утилиты -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <!-- Face-api.js -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <!-- TensorFlow.js и COCO-SSD -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <script>
    // Элементы страницы
    const videoElement = document.getElementById('video');
    const outputCanvas = document.getElementById('output');
    const drawCanvas = document.getElementById('drawLayer');
    const overlayCanvas = document.getElementById('overlay');
    const infoDiv = document.getElementById('info');
    const fullscreenBtn = document.getElementById('fullscreenBtn');
    const switchCameraBtn = document.getElementById('switchCameraBtn');
    const outputCtx = outputCanvas.getContext('2d');
    const drawCtx = drawCanvas.getContext('2d');
    const overlayCtx = overlayCanvas.getContext('2d');

    // Глобальные переменные
    let currentFacingMode = 'user'; // начально передняя камера
    let stream = null;
    let handsGestureActive = false;
    let fistCount = 0;
    let lastFistState = false;
    let lastTimeFist = 0;
    let drawingActive = false;
    let faceDetections = [];
    let objectDetections = [];
    let cocoModel = null;

    // Функция для установки размеров canvas
    function resizeCanvases() {
      const width = videoElement.videoWidth || window.innerWidth;
      const height = videoElement.videoHeight || window.innerHeight;
      [outputCanvas, drawCanvas, overlayCanvas].forEach(canvas => {
        canvas.width = width;
        canvas.height = height;
      });
    }

    // Запрос доступа к камере с заданным facingMode
    async function startCamera() {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: currentFacingMode }
        });
        videoElement.srcObject = stream;
      } catch (err) {
        console.error("Ошибка доступа к камере:", err);
      }
    }

    // Обработчик кнопки полноэкранного режима
    fullscreenBtn.addEventListener('click', () => {
      if (document.fullscreenElement) {
        document.exitFullscreen();
      } else {
        document.getElementById('container').requestFullscreen();
      }
    });

    // Обработчик переключения камеры
    switchCameraBtn.addEventListener('click', () => {
      currentFacingMode = (currentFacingMode === 'user') ? 'environment' : 'user';
      startCamera();
    });

    // --- Mediapipe Hands ---
    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });
    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.7
    });

    hands.onResults(results => {
      if (!outputCanvas.width || !outputCanvas.height) {
        resizeCanvases();
      }
      // Отрисовка видео на outputCanvas
      outputCtx.save();
      outputCtx.clearRect(0, 0, outputCanvas.width, outputCanvas.height);
      outputCtx.drawImage(results.image, 0, 0, outputCanvas.width, outputCanvas.height);

      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];

        // Вычисляем ограничивающий прямоугольник для руки
        let minX = 1, minY = 1, maxX = 0, maxY = 0;
        landmarks.forEach(pt => {
          if (pt.x < minX) minX = pt.x;
          if (pt.y < minY) minY = pt.y;
          if (pt.x > maxX) maxX = pt.x;
          if (pt.y > maxY) maxY = pt.y;
        });
        const boxX = minX * outputCanvas.width;
        const boxY = minY * outputCanvas.height;
        const boxW = (maxX - minX) * outputCanvas.width;
        const boxH = (maxY - minY) * outputCanvas.height;
        // Рисуем зелёную рамку для руки
        outputCtx.strokeStyle = 'lime';
        outputCtx.lineWidth = 3;
        outputCtx.strokeRect(boxX, boxY, boxW, boxH);

        // --- Логика распознавания жестов ---
        const now = Date.now();
        if (now - lastTimeFist > 700) {
          const fist = isFist(landmarks);
          if (fist !== lastFistState) {
            lastFistState = fist;
            lastTimeFist = now;
            if (fist) {
              fistCount++;
              console.log("Кулак обнаружен. Счёт:", fistCount);
            }
          }
        }
        // Если два раза сжат кулак и затем указательный палец вытянут – активировать режим рисования
        if (!drawingActive && fistCount >= 2 && isIndexPointing(landmarks)) {
          drawingActive = true;
          console.log("Режим рисования активирован");
        }
        // В режиме рисования – рисуем линию по движению указательного пальца
        if (drawingActive) {
          const indexTip = landmarks[8];
          const x = indexTip.x * drawCanvas.width;
          const y = indexTip.y * drawCanvas.height;
          drawCtx.fillStyle = 'black';
          drawCtx.beginPath();
          drawCtx.arc(x, y, 4, 0, 2 * Math.PI);
          drawCtx.fill();
        }
        // Если жест OK (указательный и большой пальцы рядом) – очистить рисунок и сбросить режим
        if (drawingActive && isOkGesture(landmarks)) {
          console.log("Жест OK обнаружен, очистка холста");
          drawCtx.clearRect(0, 0, drawCanvas.width, drawCanvas.height);
          drawingActive = false;
          fistCount = 0;
        }
      }
      outputCtx.restore();
    });

    // Простая эвристика: проверка вытянут ли палец
    function isFingerExtended(landmarks, pipIdx, tipIdx) {
      const pip = landmarks[pipIdx];
      const tip = landmarks[tipIdx];
      const wrist = landmarks[0];
      const distTip = Math.hypot(tip.x - wrist.x, tip.y - wrist.y);
      const distPip = Math.hypot(pip.x - wrist.x, pip.y - wrist.y);
      return distTip > distPip * 1.3;
    }

    function isFist(landmarks) {
      const fingers = [
        { pip: 6, tip: 8 },
        { pip: 10, tip: 12 },
        { pip: 14, tip: 16 },
        { pip: 18, tip: 20 }
      ];
      let thumbExtended = isFingerExtended(landmarks, 2, 4);
      let otherFingersFolded = fingers.every(f => !isFingerExtended(landmarks, f.pip, f.tip));
      return (!thumbExtended) && otherFingersFolded;
    }

    function isIndexPointing(landmarks) {
      const indexExtended = isFingerExtended(landmarks, 6, 8);
      const otherFingers = [
        { pip: 10, tip: 12 },
        { pip: 14, tip: 16 },
        { pip: 18, tip: 20 }
      ];
      let othersFolded = otherFingers.every(f => !isFingerExtended(landmarks, f.pip, f.tip));
      return indexExtended && othersFolded;
    }

    function isOkGesture(landmarks) {
      const thumbTip = landmarks[4];
      const indexTip = landmarks[8];
      const dist = Math.hypot(thumbTip.x - indexTip.x, thumbTip.y - indexTip.y);
      return dist < 0.05;
    }

    // Инициализация камеры для Mediapipe
    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await hands.send({ image: videoElement });
      },
      width: 640,
      height: 480
    });

    // --- Face-api.js ---
    async function loadFaceModels() {
      // Модели должны находиться в папке "models" (настроить путь при необходимости)
      await faceapi.nets.tinyFaceDetector.loadFromUri('models');
      await faceapi.nets.ageGenderNet.loadFromUri('models');
      await faceapi.nets.faceExpressionNet.loadFromUri('models');
      console.log("Модели face‑api загружены");
    }

    async function detectFaces() {
      if (videoElement.readyState >= 2) {
        const detections = await faceapi.detectAllFaces(videoElement, new faceapi.TinyFaceDetectorOptions())
          .withFaceExpressions()
          .withAgeAndGender();
        faceDetections = detections;
      }
    }

    // --- COCO-SSD (обнаружение объектов) ---
    async function loadCocoModel() {
      cocoModel = await cocoSsd.load();
      console.log("Модель COCO‑SSD загружена");
    }

    async function detectObjects() {
      if (videoElement.readyState >= 2 && cocoModel) {
        const predictions = await cocoModel.detect(videoElement);
        objectDetections = predictions;
      }
    }

    // Отрисовка рамок для лиц и объектов на overlayCanvas
    function drawOverlays() {
      overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
      
      // Рисуем рамки для лиц (жёлтым)
      faceDetections.forEach(det => {
        const { x, y, width, height } = det.detection.box;
        overlayCtx.strokeStyle = 'yellow';
        overlayCtx.lineWidth = 2;
        overlayCtx.strokeRect(x, y, width, height);
        const age = Math.round(det.age);
        // Определяем доминирующую эмоцию
        const expressions = det.expressions;
        const dominantExp = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
        overlayCtx.fillStyle = 'yellow';
        overlayCtx.font = '16px sans-serif';
        overlayCtx.fillText(`Возраст: ${age}, ${dominantExp}`, x, y - 5);
      });
      
      // Рисуем рамки для объектов
      const dangerous = ['knife', 'scissors', 'gun'];
      const food = ['apple', 'banana', 'pizza', 'orange', 'broccoli', 'carrot'];
      objectDetections.forEach(obj => {
        const { bbox, class: className, score } = obj;
        let color = 'yellow';
        let label = className;
        if (dangerous.includes(className.toLowerCase())) {
          color = 'red';
          label = `опасный: ${className}`;
        } else if (food.includes(className.toLowerCase())) {
          color = 'green';
          label = `еда: ${className}`;
        }
        overlayCtx.strokeStyle = color;
        overlayCtx.lineWidth = 2;
        overlayCtx.strokeRect(bbox[0], bbox[1], bbox[2], bbox[3]);
        overlayCtx.fillStyle = color;
        overlayCtx.font = '16px sans-serif';
        overlayCtx.fillText(label, bbox[0], bbox[1] - 5);
      });
    }

    // Главный цикл для отрисовки overlay и периодического запуска детекции лиц/объектов
    function animate() {
      drawOverlays();
      requestAnimationFrame(animate);
    }

    // Периодически обновляем данные о лицах и объектах (например, каждые 500мс)
    setInterval(detectFaces, 500);
    setInterval(detectObjects, 500);

    // Инициализация всех модулей
    async function init() {
      await startCamera();
      await loadFaceModels();
      await loadCocoModel();
      camera.start();
      animate();
    }
    init();

    // Обновление размеров при изменении окна
    window.addEventListener('resize', resizeCanvases);
  </script>
</body>
</html>
