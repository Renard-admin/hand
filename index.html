<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Расширенное распознавание: руки, лица, объекты</title>
  <style>
    * { margin: 0; padding: 0; }
    body, html { overflow: hidden; background: #333; color: #fff; font-family: sans-serif; }
    #container {
      position: relative;
      width: 100vw;
      height: 100vh;
      background: #000;
    }
    video, canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      /* Зеркальный эффект можно отключить, если убрать scaleX(-1) */
      transform: scaleX(-1);
    }
    /* Контрольная панель */
    #info {
      position: absolute;
      top: 10px;
      left: 10px;
      background: rgba(0,0,0,0.5);
      padding: 5px 10px;
      border-radius: 4px;
      z-index: 30;
    }
    button {
      position: absolute;
      top: 10px;
      padding: 10px 20px;
      background: rgba(0,0,0,0.7);
      color: #fff;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 16px;
      z-index: 30;
    }
    #fullscreenBtn { right: 10px; }
    #switchCameraBtn { right: 150px; }
    button:hover {
      background: rgba(0,0,0,0.9);
    }
  </style>
</head>
<body>
  <div id="container">
    <!-- Видеопоток -->
    <video id="video" autoplay playsinline muted></video>
    <!-- Canvas для отрисовки видео и результатов распознавания рук -->
    <canvas id="output"></canvas>
    <!-- Canvas для рисования линий (режим рисования) -->
    <canvas id="drawLayer"></canvas>
    <!-- Дополнительный canvas для оверлеев: лица и объекты -->
    <canvas id="overlay"></canvas>
    <!-- Информационный блок -->
    <div id="info">
      Жесты: два раза сжать/разжать кулак + указательный = начать рисование; жест OK = очистить<br>
      Полный экран и смена камеры доступны через кнопки.
    </div>
    <button id="fullscreenBtn">Полный экран</button>
    <button id="switchCameraBtn">Сменить камеру</button>
  </div>

  <!-- Подключение библиотек -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <script>
    // Элементы страницы и контексты отрисовки
    const videoElement = document.getElementById('video');
    const outputCanvas = document.getElementById('output');
    const drawCanvas = document.getElementById('drawLayer');
    const overlayCanvas = document.getElementById('overlay');
    const infoDiv = document.getElementById('info');
    const fullscreenBtn = document.getElementById('fullscreenBtn');
    const switchCameraBtn = document.getElementById('switchCameraBtn');

    const outputCtx = outputCanvas.getContext('2d');
    const drawCtx = drawCanvas.getContext('2d');
    const overlayCtx = overlayCanvas.getContext('2d');

    // Переменные для работы с камерой
    let currentStream = null;
    let facingMode = "user"; // "user" или "environment"

    // Функция установки размеров всех canvas
    function resizeCanvases() {
      const width = videoElement.videoWidth || window.innerWidth;
      const height = videoElement.videoHeight || window.innerHeight;
      outputCanvas.width = width;
      outputCanvas.height = height;
      drawCanvas.width = width;
      drawCanvas.height = height;
      overlayCanvas.width = width;
      overlayCanvas.height = height;
    }

    // Функция запуска видеопотока с нужными настройками
    async function startCamera() {
      if (currentStream) {
        currentStream.getTracks().forEach(track => track.stop());
      }
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: facingMode },
          audio: false
        });
        currentStream = stream;
        videoElement.srcObject = stream;
        videoElement.onloadedmetadata = () => {
          resizeCanvases();
          // Запускаем цикл обработки видео для распознавания рук
          processVideo();
        };
      } catch (err) {
        console.error("Ошибка доступа к камере:", err);
      }
    }

    // Обработчики кнопок
    fullscreenBtn.addEventListener('click', () => {
      if (document.fullscreenElement) {
        document.exitFullscreen();
      } else {
        document.getElementById('container').requestFullscreen();
      }
    });

    switchCameraBtn.addEventListener('click', () => {
      // Переключаем режим: если сейчас user, то environment и наоборот
      facingMode = (facingMode === "user") ? "environment" : "user";
      startCamera();
    });

    // --- Mediapipe Hands и логика жестов ---
    // Параметры для распознавания жестов
    let fistCount = 0;
    let gestureActive = false;
    let lastFistState = false;
    let lastTimeFist = 0;

    // Простая эвристика для определения вытянутого пальца
    function isFingerExtended(landmarks, pipIdx, tipIdx) {
      const pip = landmarks[pipIdx];
      const tip = landmarks[tipIdx];
      const wrist = landmarks[0];
      const distTip = Math.hypot(tip.x - wrist.x, tip.y - wrist.y);
      const distPip = Math.hypot(pip.x - wrist.x, pip.y - wrist.y);
      return distTip > distPip * 1.3;
    }

    // Определение жеста "кулак" – все пальцы (кроме, возможно, большого) не вытянуты
    function isFist(landmarks) {
      const fingers = [
        { pip: 6, tip: 8 },   // указательный
        { pip: 10, tip: 12 }, // средний
        { pip: 14, tip: 16 }, // безымянный
        { pip: 18, tip: 20 }  // мизинец
      ];
      let thumbExtended = isFingerExtended(landmarks, 2, 4);
      let otherFingersFolded = fingers.every(f => !isFingerExtended(landmarks, f.pip, f.tip));
      return (!thumbExtended) && otherFingersFolded;
    }

    // Жест "указательный" – указательный палец вытянут, остальные нет
    function isIndexPointing(landmarks) {
      const indexExtended = isFingerExtended(landmarks, 6, 8);
      const otherFingers = [
        { pip: 10, tip: 12 },
        { pip: 14, tip: 16 },
        { pip: 18, tip: 20 }
      ];
      let othersFolded = otherFingers.every(f => !isFingerExtended(landmarks, f.pip, f.tip));
      return indexExtended && othersFolded;
    }

    // Жест "OK" – расстояние между большим и указательным пальцами маленькое
    function isOkGesture(landmarks) {
      const thumbTip = landmarks[4];
      const indexTip = landmarks[8];
      const dx = thumbTip.x - indexTip.x;
      const dy = thumbTip.y - indexTip.y;
      const dist = Math.hypot(dx, dy);
      return dist < 0.05;
    }

    // Инициализация Mediapipe Hands
    const hands = new Hands({
      locateFile: (file) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
      }
    });
    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.7
    });
    hands.onResults((results) => {
      if (!outputCanvas.width || !outputCanvas.height) {
        resizeCanvases();
      }
      // Отрисовка видео (уже обработанного Mediapipe)
      outputCtx.save();
      outputCtx.clearRect(0, 0, outputCanvas.width, outputCanvas.height);
      outputCtx.drawImage(results.image, 0, 0, outputCanvas.width, outputCanvas.height);

      // Если обнаружена рука, рисуем рамку и анализируем жесты
      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];

        // Вычисляем ограничивающий прямоугольник руки
        let minX = 1, minY = 1, maxX = 0, maxY = 0;
        landmarks.forEach(pt => {
          if (pt.x < minX) minX = pt.x;
          if (pt.y < minY) minY = pt.y;
          if (pt.x > maxX) maxX = pt.x;
          if (pt.y > maxY) maxY = pt.y;
        });
        const boxX = minX * outputCanvas.width;
        const boxY = minY * outputCanvas.height;
        const boxW = (maxX - minX) * outputCanvas.width;
        const boxH = (maxY - minY) * outputCanvas.height;
        // Рисуем зелёную рамку для руки
        outputCtx.strokeStyle = 'lime';
        outputCtx.lineWidth = 3;
        outputCtx.strokeRect(boxX, boxY, boxW, boxH);

        // Логика распознавания жестов
        const now = Date.now();
        if (now - lastTimeFist > 700) {  // дебаунс
          const fist = isFist(landmarks);
          if (fist !== lastFistState) {
            lastFistState = fist;
            lastTimeFist = now;
            if (fist) {
              fistCount++;
              console.log("Кулак обнаружен. Счёт:", fistCount);
            }
          }
        }
        if (!gestureActive && fistCount >= 2 && isIndexPointing(landmarks)) {
          gestureActive = true;
          console.log("Режим рисования активирован");
        }
        if (gestureActive) {
          const indexTip = landmarks[8];
          const x = indexTip.x * drawCanvas.width;
          const y = indexTip.y * drawCanvas.height;
          // Рисуем черную точку (линия формируется при движении)
          drawCtx.fillStyle = 'black';
          drawCtx.beginPath();
          drawCtx.arc(x, y, 4, 0, 2 * Math.PI);
          drawCtx.fill();
        }
        if (gestureActive && isOkGesture(landmarks)) {
          console.log("Жест OK обнаружен, очистка рисунка");
          drawCtx.clearRect(0, 0, drawCanvas.width, drawCanvas.height);
          gestureActive = false;
          fistCount = 0;
        }
      }
      outputCtx.restore();
    });

    // Запускаем цикл для отправки кадров из video в Mediapipe Hands
    async function processVideo() {
      if (videoElement.readyState >= 2) {
        await hands.send({ image: videoElement });
      }
      requestAnimationFrame(processVideo);
    }

    // --- Распознавание лиц с помощью face‑api.js ---
    // Загрузка моделей. Для демонстрации модели ожидаются в папке "/models"
    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
      faceapi.nets.ageGenderNet.loadFromUri('/models'),
      faceapi.nets.faceExpressionNet.loadFromUri('/models')
    ]).then(() => {
      console.log("Face‑api модели загружены");
    });

    async function detectFaces() {
      if (videoElement.readyState < 2) return;
      const detections = await faceapi.detectAllFaces(videoElement, new faceapi.TinyFaceDetectorOptions())
                                      .withAgeAndGender()
                                      .withFaceExpressions();
      // Очищаем оверлей перед новой отрисовкой
      overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
      detections.forEach(d => {
        const { x, y, width, height } = d.detection.box;
        overlayCtx.strokeStyle = "yellow";
        overlayCtx.lineWidth = 2;
        overlayCtx.strokeRect(x, y, width, height);
        // Определяем доминирующую эмоцию
        const expressions = d.expressions;
        const dominantEmotion = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
        const age = Math.round(d.age);
        overlayCtx.fillStyle = "yellow";
        overlayCtx.font = "16px sans-serif";
        overlayCtx.fillText(`Возраст: ${age}, ${dominantEmotion}`, x, y - 10);
      });
    }
    // Обновляем распознавание лиц раз в 1 секунду
    setInterval(detectFaces, 1000);

    // --- Распознавание объектов с помощью COCO-SSD (TensorFlow.js) ---
    let objectModel;
    async function loadObjectModel() {
      objectModel = await cocoSsd.load();
      console.log("Модель объектов загружена");
    }
    async function detectObjects() {
      if (!objectModel || videoElement.readyState < 2) return;
      const predictions = await objectModel.detect(videoElement);
      predictions.forEach(p => {
        const [x, y, w, h] = p.bbox;
        let color = "yellow";
        let labelPrefix = "";
        // Определяем опасные объекты
        const dangerous = ["knife", "pistol", "scissors"];
        // Пример списка еды
        const food = ["apple", "banana", "pizza", "orange", "sandwich"];
        if (dangerous.includes(p.class.toLowerCase())) {
          color = "red";
          labelPrefix = "опасный: ";
        } else if (food.includes(p.class.toLowerCase())) {
          color = "green";
          labelPrefix = "еда: ";
        }
        overlayCtx.strokeStyle = color;
        overlayCtx.lineWidth = 2;
        overlayCtx.strokeRect(x, y, w, h);
        overlayCtx.fillStyle = color;
        overlayCtx.font = "16px sans-serif";
        overlayCtx.fillText(`${labelPrefix}${p.class}`, x, y > 20 ? y - 5 : y + 15);
      });
    }
    // Обновляем распознавание объектов раз в 1 секунду
    setInterval(detectObjects, 1000);
    loadObjectModel();

    // --- Инициализация ---
    // Запуск камеры при загрузке страницы
    startCamera();

    // При изменении размера окна обновляем размеры canvas
    window.addEventListener('resize', resizeCanvases);
  </script>
</body>
</html>
